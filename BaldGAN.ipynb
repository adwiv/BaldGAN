{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYJ-56z0WMqX",
        "outputId": "13ff1150-1b31-4d3f-8986-b4dbeae2d2e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "Tesla T4\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.0 GB\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "print()\n",
        "\n",
        "#Additional Info when using cuda\n",
        "if device.type == 'cuda':\n",
        "    print(torch.cuda.get_device_name(0))\n",
        "    print('Memory Usage:')\n",
        "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
        "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "pZLsz-42W4Y_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --progress-bar off face_alignment tensorrt tensorflow-gpu==2.8.0"
      ],
      "metadata": {
        "id": "VT3C09JPcPf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/adwiv/BaldGAN.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSpQm8moXVQm",
        "outputId": "cf6c9504-d5bf-4013-99a9-5ca54491ea6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'BaldGAN'...\n",
            "remote: Enumerating objects: 1094, done.\u001b[K\n",
            "remote: Counting objects: 100% (94/94), done.\u001b[K\n",
            "remote: Compressing objects: 100% (76/76), done.\u001b[K\n",
            "remote: Total 1094 (delta 20), reused 89 (delta 18), pack-reused 1000\u001b[K\n",
            "Receiving objects: 100% (1094/1094), 222.18 MiB | 4.58 MiB/s, done.\n",
            "Resolving deltas: 100% (23/23), done.\n",
            "Updating files: 100% (117/117), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd BaldGAN/pretrained_models/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPfv93sAXfT7",
        "outputId": "6d8a2f1d-b827-45c4-f388-455d359471f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/BaldGAN/pretrained_models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 14w4qJ3OMoq9UA2-rxP5bEXwds_nWhdd5 #stylegan generetor\n",
        "!gdown 1PHLeHmzeocleS0cvJ3237ulXxayrDwVD #stylegan encoder\n",
        "!gdown 19sUOuCOuK64t8FOs1YPdZrKncVT1LQsl #inpainting1\n",
        "!gdown 1xEuGtWv2pwPHRUtZfpYw32BnnvoCg3kW #inpainting2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCLUpZwdXu3o",
        "outputId": "f008b01c-046e-4eae-d025-4465a0d88215"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=14w4qJ3OMoq9UA2-rxP5bEXwds_nWhdd5\n",
            "To: /content/BaldGAN/pretrained_models/styleganinv_ffhq256_generator.pth\n",
            "100% 119M/119M [00:08<00:00, 14.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1PHLeHmzeocleS0cvJ3237ulXxayrDwVD\n",
            "To: /content/BaldGAN/pretrained_models/styleganinv_ffhq256_encoder.pth\n",
            "100% 661M/661M [00:10<00:00, 61.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19sUOuCOuK64t8FOs1YPdZrKncVT1LQsl\n",
            "To: /content/BaldGAN/pretrained_models/ckpt-25.data-00000-of-00001\n",
            "100% 157M/157M [00:06<00:00, 23.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1xEuGtWv2pwPHRUtZfpYw32BnnvoCg3kW\n",
            "To: /content/BaldGAN/pretrained_models/ckpt-25.index\n",
            "100% 8.39k/8.39k [00:00<00:00, 37.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls -lh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8oszla78OBN",
        "outputId": "6749de89-73f5-416a-d4fe-9ebc08fd6464"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 1.1G\n",
            "-rw-r--r-- 1 root root  51M Dec  6 12:33 79999_iter.pth\n",
            "-rw-r--r-- 1 root root 150M Dec  6 12:33 ckpt-25.data-00000-of-00001\n",
            "-rw-r--r-- 1 root root 8.2K Dec  6 12:33 ckpt-25.index\n",
            "-rw-r--r-- 1 root root 713K Dec  6 12:33 mmod_human_face_detector.dat\n",
            "-rw-r--r-- 1 root root  96M Dec  6 12:33 shape_predictor_68_face_landmarks.dat\n",
            "-rw-r--r-- 1 root root 631M Dec  6 12:33 styleganinv_ffhq256_encoder.pth\n",
            "-rw-r--r-- 1 root root 114M Dec  6 12:33 styleganinv_ffhq256_generator.pth\n",
            "-rw-r--r-- 1 root root  57M Dec  6 12:33 vgg16.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/BaldGAN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gjp5Xesiad-V",
        "outputId": "c30e573c-8639-4e08-f1df-84a1bc87cd93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/BaldGAN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --test_dir ./samples/test_data/ -o ./samples/test_data_results2  --save_align"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFIc6XQKbhkk",
        "outputId": "cf19c452-e16a-479d-c760-4e25a6944476"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading models for hypergan inpainting.\n",
            "2023-12-06 12:40:37.463888: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).discriminator.layer_with_weights-0.kernel\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).discriminator.layer_with_weights-0.bias\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).discriminator.layer_with_weights-1.kernel\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).discriminator.layer_with_weights-1.bias\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).discriminator.layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).discriminator.layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).discriminator.layer_with_weights-3.kernel\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).discriminator.layer_with_weights-3.bias\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).discriminator.layer_with_weights-4.kernel\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).discriminator.layer_with_weights-4.bias\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).discriminator.layer_with_weights-5.kernel\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).discriminator.layer_with_weights-5.bias\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).discriminator.layer_with_weights-6.kernel\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).discriminator.layer_with_weights-6.bias\n",
            "found 7 images in the folder\n"
          ]
        }
      ]
    }
  ]
}